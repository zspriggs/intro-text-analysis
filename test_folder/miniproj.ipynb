{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Project\n",
    "\n",
    "Dispersion analysis project\n",
    "Comparing Pausanias and Herodotus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling a Corpus\n",
    "\n",
    "The first step to this project will be assembling a small corpus for analysis. Given that we are interested in the linguistic differences between Pausanias and Herodotus, we need to find the URN for Herodotus's histories: urn:cts:greekLit:tlg0016.tlg001.perseus-grc2\n",
    "\n",
    "Once we have the URN, we can fetch the file we need. \n",
    "\n",
    "Let's start with some exploration into each dataset. \n",
    "\n",
    "Like how we did in Week 02, we'll use MyCapytain and Pandas to open up each dataset and turn them into a format we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "\n",
    "with open(\"../tei/tlg0525.tlg001.perseus-grc2.xml\") as f:\n",
    "    pausanias_text = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0525.tlg001.perseus-grc2\", resource=f)\n",
    "\n",
    "with open(\"./tlg0016.tlg001.perseus-grc2.xml\") as f:\n",
    "    herodotus_text = CapitainsCtsText(urn=\"urn:cts:greekList:tlg0016.tlg001.perseus-grc2\", resource=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    "\n",
    "\n",
    "#pausanias\n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    "\n",
    "for ref in pausanias_text.getReffs(level=len(pausanias_text.citation)):\n",
    "    urn = f\"{pausanias_text.urn}:{ref}\"\n",
    "    node = pausanias_text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    "\n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)\n",
    "\n",
    "#herodotus\n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    "\n",
    "for ref in herodotus_text.getReffs(level=len(herodotus_text.citation)):\n",
    "    urn = f\"{herodotus_text.urn}:{ref}\"\n",
    "    node = herodotus_text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    "\n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "herodotus_df = pd.DataFrame(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting tokens, types, etc\n",
    "\n",
    "With dataframes for each work created, let's get an idea of how many tokens are in each corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184838"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pausanias_df['whitespaced_tokens'] = pausanias_df['unannotated_strings'].str.split()\n",
    "pausanias_df['whitespaced_tokens'].explode().count()\n",
    "\n",
    "herodotus_df['whitespaced_tokens'] = herodotus_df['unannotated_strings'].str.split()\n",
    "herodotus_df['whitespaced_tokens'].explode().count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we have an idea of the number of tokens in each corpus. Pausanias has \n",
    "In week 3, we worked on counting the number of occurences of the definite article in Pausanias using an nlp pipeline, then determining the relative frequency of the definite article.. Let's repeat these steps for both Pausanias and Herodotus, just to explore the data a little further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/intro-text-analysis/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/workspaces/intro-text-analysis/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"grc_proiel_sm\", disable=[\"ner\"])\n",
    "\n",
    "#pausanias\n",
    "raw_texts_p = [t for t in pausanias_df['unannotated_strings']]\n",
    "annotated_texts_p = nlp.pipe(raw_texts_p, batch_size=100)\n",
    "\n",
    "\n",
    "#herodotus\n",
    "raw_texts_h= [t for t in herodotus_df['unannotated_strings']]\n",
    "annotated_texts_h = nlp.pipe(raw_texts_h, batch_size=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250.8047232159593\n",
      "1170.7162996372285\n"
     ]
    }
   ],
   "source": [
    "#pausanias\n",
    "pausanias_df['nlp_docs'] = list(annotated_texts_p)\n",
    "definite_article_p = [t for t in pausanias_df['nlp_docs'].explode() if t.lemma_ == \"ὁ\"]\n",
    "n_def_article_p = len(definite_article_p)\n",
    "n_tokens_p = len([t for t in pausanias_df['nlp_docs'].explode()])\n",
    "\n",
    "#herodotus\n",
    "herodotus_df['nlp_docs'] = list(annotated_texts_h)\n",
    "definite_article_h = [t for t in herodotus_df['nlp_docs'].explode() if t.lemma_ == \"ὁ\"]\n",
    "n_def_article_h = len(definite_article_h)\n",
    "n_tokens_h = len([t for t in herodotus_df['nlp_docs'].explode()])\n",
    "\n",
    "basis = 10_000\n",
    "\n",
    "rf_definite_article_in_pausanias = (n_def_article_p / n_tokens_p) * basis\n",
    "rf_definite_article_in_herodotus = (n_def_article_h / n_tokens_h) * basis\n",
    "\n",
    "print(rf_definite_article_in_pausanias)\n",
    "print(rf_definite_article_in_herodotus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm... why the difference? Surely we can't expect the relative frequency of the definite article to be the exact same in two different works. But Pausanias does use the deinite article more, so I'm curious whether this is statistically significant. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
